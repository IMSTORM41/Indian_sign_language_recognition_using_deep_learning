{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1624104957416,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "OE8pu0xH8iPQ",
    "outputId": "ec3461a1-698d-46c4-8de3-67f40ccb33dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount (\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1624106419497,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "mD-jcewc9SdQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, TimeDistributed, LSTM, Input, BatchNormalization, Conv2D, MaxPooling2D, Reshape, Conv1D, GlobalAveragePooling1D, MaxPooling1D, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.losses import categorical_crossentropy\n",
    "import tensorflow_hub as hub\n",
    "from PIL import Image\n",
    "import gzip\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import spacy\n",
    "import h5py\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import gzip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1624106420139,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "CWT2RRRY82sI"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624106421125,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "eDqKt3ss8-Ob"
   },
   "outputs": [],
   "source": [
    "path_gloss_files = '/content/drive/MyDrive/Colab Notebooks/phoenix14t.pami0.train.annotations_only.gzip'\n",
    "path_dev_gloss = '/content/drive/MyDrive/Colab Notebooks/phoenix14t.pami0.dev.annotations_only.gzip'\n",
    "path_test_gloss = '/content/drive/MyDrive/Colab Notebooks/phoenix14t.pami0.test.annotations_only.gzip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1XYbKOm9G-q"
   },
   "source": [
    "# reading glooss files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624106421719,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "-NfB96o69NPS"
   },
   "outputs": [],
   "source": [
    "with gzip.open(path_gloss_files,'rb') as f:\n",
    "  annotation_gloss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1624106421719,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "_Maxe0E_9PKb"
   },
   "outputs": [],
   "source": [
    "with gzip.open(path_dev_gloss,'rb') as f:\n",
    "  annotation_dev = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624106422356,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "GFVfHiTt9WSb"
   },
   "outputs": [],
   "source": [
    "with gzip.open(path_test_gloss,'rb')as f :\n",
    "  annotation_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1624106423435,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "5Y8KlhLX9Xl8"
   },
   "outputs": [],
   "source": [
    "annotation_gloss = pd.DataFrame(annotation_gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1624106424035,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "3E5IxgSg9ZOE"
   },
   "outputs": [],
   "source": [
    "annotation_gloss_dev = pd.DataFrame(annotation_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1624106424036,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "EA2A04qS9a3T"
   },
   "outputs": [],
   "source": [
    "annotation_gloss_test = pd.DataFrame(annotation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzYhzSf09e1j"
   },
   "source": [
    "# preprocessing gloes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "executionInfo": {
     "elapsed": 4021,
     "status": "ok",
     "timestamp": 1624106431255,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "skuo3Gjq9k-a"
   },
   "outputs": [],
   "source": [
    "for i in range(len(annotation_gloss)):\n",
    "  annotation_gloss.iloc[i,2] = 'startseq '+annotation_gloss.iloc[i,2].lower() + ' endseq'\n",
    "  annotation_gloss.iloc[i,3] = 'startseq '+annotation_gloss.iloc[i,3].lower() + ' endseq'\n",
    "  annotation_gloss.iloc[i,3] = annotation_gloss.iloc[i,3].replace(' .','')\n",
    "  #annotation_gloss.iloc[i,3] =annotation_gloss.iloc[i,3][-2].replace(' ','')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1624106431257,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "ZBIUfGnJ9mOS"
   },
   "outputs": [],
   "source": [
    "for i in range(len(annotation_gloss_dev)):\n",
    "  annotation_gloss_dev.iloc[i,2] = 'startseq '+annotation_gloss_dev.iloc[i,2].lower() + ' endseq'\n",
    "  annotation_gloss_dev.iloc[i,3] = 'startseq '+annotation_gloss_dev.iloc[i,3].lower() + ' endseq'\n",
    "  annotation_gloss_dev.iloc[i,3] = annotation_gloss_dev.iloc[i,3].replace(' .','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1624106431257,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "gVu6LHkE9niC"
   },
   "outputs": [],
   "source": [
    "for i in range(len(annotation_gloss_test)):\n",
    "  annotation_gloss_test.iloc[i,2] = 'startseq '+annotation_gloss_test.iloc[i,2].lower() + ' endseq'\n",
    "  annotation_gloss_test.iloc[i,3] = 'startseq '+annotation_gloss_test.iloc[i,3].lower() + ' endseq'\n",
    "  annotation_gloss_test.iloc[i,3] = annotation_gloss_test.iloc[i,3].replace(' .','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1624106431258,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "Y1yyRI-RAqZf",
    "outputId": "aabac807-4f1c-43e9-a17e-46c472ea2504"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'startseq ort regen durch regen koennen ueberschwemmung koennen endseq'"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_gloss.iloc[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1624106431259,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "N6S3_GnYAzZx",
    "outputId": "6085ecaa-c6e9-48ad-a0da-bc0d3a0dbc36"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'startseq mancherorts regnet es auch länger und ergiebig auch lokale überschwemmungen sind wieder möglich endseq'"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_gloss.iloc[1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1624104964830,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "SKeGGMdNAzIm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DR8xlnZB9o3K"
   },
   "source": [
    "# calculating max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1624108035992,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "Ou1QKgQN9uQS"
   },
   "outputs": [],
   "source": [
    "gloss_gloss = []\n",
    "for i in range(7096):\n",
    "  gloss_gloss.append(annotation_gloss.iloc[i,3])\n",
    "  gloss_gloss.append(annotation_gloss.iloc[i,2])\n",
    "for i in range(len(annotation_gloss_dev)):\n",
    "  gloss_gloss.append(annotation_gloss_dev.iloc[i,3])\n",
    "  gloss_gloss.append(annotation_gloss_dev.iloc[i,2])\n",
    "for i in range(len(annotation_gloss_test)):\n",
    "  gloss_gloss.append(annotation_gloss_test.iloc[i,3])\n",
    "  gloss_gloss.append(annotation_gloss_test.iloc[i,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 590,
     "status": "ok",
     "timestamp": 1624108039187,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "RonIM9NM9y-h",
    "outputId": "ef1645b2-6c28-4691-94e8-025dd1853f28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16514"
      ]
     },
     "execution_count": 177,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gloss_gloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1624108046388,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "xjRX53IT9vhS"
   },
   "outputs": [],
   "source": [
    "length_check = []\n",
    "for i in range (len(gloss_gloss)):\n",
    "  length_check.append(gloss_gloss[i].split(' '))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1624108051723,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "Q3vthC6K9xSC"
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(len(length_check)):\n",
    "  if(len(length_check[i])>count):\n",
    "    count = len(length_check[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624108053075,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "hHE5C9ZV91ka",
    "outputId": "177a866c-cde5-4c88-e8b7-90a0a9f34d75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 180,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1624107907167,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "niJ7wUxIX97Q",
    "outputId": "fab4bd12-7d9f-4001-f92e-d8e5b5ab8207"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq',\n",
       " 'und',\n",
       " 'nun',\n",
       " 'die',\n",
       " 'wettervorhersage',\n",
       " 'für',\n",
       " 'morgen',\n",
       " 'donnerstag',\n",
       " 'den',\n",
       " 'zwölften',\n",
       " 'august',\n",
       " 'endseq']"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_check[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1624107941843,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "xAIR4plVXyqY"
   },
   "outputs": [],
   "source": [
    "for i in range(len(length_check)):\n",
    "  for j in length_check[i]:\n",
    "    if(j=='region'):\n",
    "      print(\"hello\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WI1VB9b393LD"
   },
   "source": [
    "# creating unique words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "executionInfo": {
     "elapsed": 1012,
     "status": "ok",
     "timestamp": 1624108059145,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "kq9quZSj-G8z"
   },
   "outputs": [],
   "source": [
    "unique_list_text = []\n",
    "for i in range(len(length_check)):\n",
    "  for j in length_check[i]:\n",
    "    if (j not in unique_list_text):\n",
    "      unique_list_text.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1624108109375,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "zuUCqQ_q-IWL",
    "outputId": "f99b09dd-3508-4da9-9c8d-2c6af05bfa77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3606"
      ]
     },
     "execution_count": 188,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_list_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2wCQ5dQ-Jlj"
   },
   "source": [
    "# removign less frequency words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1624108069848,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "l8kffdWN-OPj"
   },
   "outputs": [],
   "source": [
    "dictionary_unq = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 37539,
     "status": "ok",
     "timestamp": 1624105002852,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "BX9QO4PA-P7T"
   },
   "outputs": [],
   "source": [
    "for i in range(len(unique_list_text)):\n",
    "  count= 0\n",
    "  for j in length_check:\n",
    "    for k in j:\n",
    "      if(unique_list_text[i] == k):\n",
    "        count+=1\n",
    "  dictionary_unq[unique_list_text[i]] = count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1624105002857,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "Ca2quua3-Q-C"
   },
   "outputs": [],
   "source": [
    "for keys in dictionary_unq.keys():\n",
    "  if dictionary_unq[keys]<5:\n",
    "    unique_list_text.remove(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1624105002857,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "wk-Bb5Zl-SFy"
   },
   "outputs": [],
   "source": [
    "unique_list_text.append('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1624106465847,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "8bj_p0-2BRcy",
    "outputId": "f02a2259-da40-47a4-82ba-165d836c2682"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3002"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_list_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXd5_KD1-TSL"
   },
   "source": [
    "# creating tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1624108120183,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "FCtsLwnQ-a_C"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(unique_list_text):\n",
    "  tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "  tokenizer.fit_on_texts(unique_list_text)\n",
    "  return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108120830,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "lXxJrFVd-cZT"
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer(unique_list_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1624108121252,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "3nXgD_ND-d16"
   },
   "outputs": [],
   "source": [
    "vocab_size_text = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108121673,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "cCmmcUSZ-fq7",
    "outputId": "e8828cdf-f9a3-403f-8cd8-5c6f4bed4e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocalb size 3434\n"
     ]
    }
   ],
   "source": [
    "print(\"vocalb size\",vocab_size_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-_iqDKM_C5b"
   },
   "source": [
    "# creating dataset for tokenizeer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1624108133382,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "zwlV5tIO_Fpa"
   },
   "outputs": [],
   "source": [
    "gloss_token = []\n",
    "text_token = []\n",
    "for i in range(len(annotation_gloss)):\n",
    "  gloss_token.append(annotation_gloss.iloc[i,2])\n",
    "  text_token.append(annotation_gloss.iloc[i,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1624108133384,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "8Rs0AD_pAYyM",
    "outputId": "a3f0ddef-b563-4c26-c513-ffc29f1a8a4c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'startseq jetzt wetter morgen donnerstag zwoelf februar endseq'"
      ]
     },
     "execution_count": 194,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gloss_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1624108134025,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "0o7euWcDAatj",
    "outputId": "3bdc8b0f-6595-4b69-d634-fcaca7219738"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'startseq und nun die wettervorhersage für morgen donnerstag den zwölften august endseq'"
      ]
     },
     "execution_count": 195,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108135805,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "2EWOHxB2_Fm0"
   },
   "outputs": [],
   "source": [
    "gloss_token_dev = []\n",
    "text_token_dev = []\n",
    "for i in range(len(annotation_gloss_dev)):\n",
    "  gloss_token_dev.append(annotation_gloss_dev.iloc[i,2])\n",
    "  text_token_dev.append(annotation_gloss_dev.iloc[i,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1624108136368,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "X6_J9lG__Fj5"
   },
   "outputs": [],
   "source": [
    "gloss_token_test = []\n",
    "text_token_test = []\n",
    "for i in range(len(annotation_gloss_test)):\n",
    "  gloss_token_test.append(annotation_gloss_test.iloc[i,2])\n",
    "  text_token_test.append(annotation_gloss_test.iloc[i,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1624108136369,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "0thNEXGi_FhB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMo2N33e-hjL"
   },
   "source": [
    "# tokenizing whole glosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1624108136778,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "ZVNs47Qh-wl6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "\t# integer encode sequences\n",
    "\tX = tokenizer.texts_to_sequences(lines)\n",
    "\t# pad sequences with 0 values\n",
    "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
    "\treturn X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108137919,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "TZri8b80-zLy"
   },
   "outputs": [],
   "source": [
    "X_train = encode_sequences(tokenizer,35,gloss_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108137920,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "OOHtL-lf-84j"
   },
   "outputs": [],
   "source": [
    "X_dev = encode_sequences(tokenizer,35,gloss_token_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1624108138564,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "_YizrD6i_NOW"
   },
   "outputs": [],
   "source": [
    "X_test = encode_sequences(tokenizer,35,gloss_token_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1624106482882,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "GiAk-ac6_QWS",
    "outputId": "92fc6cbb-f538-4a29-ff20-e63589079f2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(519, 35)"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "executionInfo": {
     "elapsed": 666,
     "status": "ok",
     "timestamp": 1624108144504,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "_C_QZYD6_SXT"
   },
   "outputs": [],
   "source": [
    "def encode_output(sequences, vocab_size):\n",
    "  ylist = list()\n",
    "  for sequence in sequences:\n",
    "    encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "    ylist.append(encoded)\n",
    "  y = np.array(ylist)\n",
    "  print(\"shape of sequences {}\".format(np.shape(sequences)))\n",
    "  y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1624108145139,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "U-agLtpP_hvp"
   },
   "outputs": [],
   "source": [
    "Y_output_token = encode_sequences(tokenizer,54,text_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "error",
     "timestamp": 1624106483606,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "RBbHk7ZV_i90",
    "outputId": "a0727cad-c768-481c-afba-50ebffd9bdbb"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-842ddc37e97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_output_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1202\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-135-90e527e91213>\u001b[0m in \u001b[0;36mencode_output\u001b[0;34m(sequences, vocab_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mylist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mylist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1202 is out of bounds for axis 1 with size 1202"
     ]
    }
   ],
   "source": [
    "Y_output = encode_output(Y_output_token,1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1624108152386,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "HYGdAEJf_koK"
   },
   "outputs": [],
   "source": [
    "Y_dev_token = encode_sequences(tokenizer,54,text_token_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1624106484186,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "NQPaTfbo_mD8",
    "outputId": "3a8f8ef9-fd50-4c2f-db43-f5851ef53cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of sequences (519, 54)\n"
     ]
    }
   ],
   "source": [
    "Y_dev = encode_output(Y_dev_token,1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1624108153684,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "S485lAwS_nQt"
   },
   "outputs": [],
   "source": [
    "Y_test_token = encode_sequences(tokenizer,54,text_token_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "error",
     "timestamp": 1624106545422,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "QdpMH1U0_oYx",
    "outputId": "c7ce3175-4c71-4411-bb9f-6fb744919700"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-a4a843e749b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1202\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-135-90e527e91213>\u001b[0m in \u001b[0;36mencode_output\u001b[0;34m(sequences, vocab_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mylist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mylist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m   \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1326 is out of bounds for axis 1 with size 1202"
     ]
    }
   ],
   "source": [
    "Y_test = encode_output(Y_test_token,1202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr-ZG0Ed_pjz"
   },
   "source": [
    "# creating a function to return index corresponding to a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1624108157374,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "dXC0QVqGBz8r"
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1624108158010,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "aJKxV-adCJjd",
    "outputId": "03ef868b-0491-4b1f-f3ea-313a8f510ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "199 ----> startseq\n",
      "41 ----> jetzt\n",
      "208 ----> wetter\n",
      "40 ----> morgen\n",
      "203 ----> donnerstag\n",
      "209 ----> zwoelf\n",
      "210 ----> februar\n",
      "207 ----> endseq\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Input Language; index to word mapping\")\n",
    "convert(tokenizer, X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108158404,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "LAfpXa5aCT4U",
    "outputId": "60f0a3a6-4ebd-4214-8893-d3dab81e2ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Language; index to word mapping\n",
      "199 ----> startseq\n",
      "39 ----> und\n",
      "200 ----> nun\n",
      "75 ----> die\n",
      "201 ----> wettervorhersage\n",
      "202 ----> für\n",
      "40 ----> morgen\n",
      "203 ----> donnerstag\n",
      "204 ----> den\n",
      "205 ----> zwölften\n",
      "206 ----> august\n",
      "207 ----> endseq\n"
     ]
    }
   ],
   "source": [
    "print (\"Target Language; index to word mapping\")\n",
    "convert( tokenizer, Y_output_token[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gp9N8RUCb6r"
   },
   "source": [
    "# creating a data batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1624108164612,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "Pq2SDWnHCxxb",
    "outputId": "32688990-81c5-44a5-f6a0-9400e1a2d3bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 210,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(X_train)\n",
    "BATCH_SIZE = 128\n",
    "steps_per_epoch = len(X_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(tokenizer.word_index)+1\n",
    "vocab_tar_size = len(tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_output_token))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108166531,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "ZJ_f7FTDTC00",
    "outputId": "db63ac8a-c6b5-4a72-8d81-ef1e1353ba49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3434"
      ]
     },
     "execution_count": 211,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_inp_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0S30Eu6E1Oq"
   },
   "source": [
    "# creating a batch of 128 dataitemx with gloss length of 35  and text length of 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1624108168811,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "JCwIGJUcC6LN",
    "outputId": "2d982dcf-0c57-4247-b543-bd83b127d1fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 35]), TensorShape([128, 54]))"
      ]
     },
     "execution_count": 212,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1624105006184,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "nzjxQYrjE0b4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7oA9J5lFCbB"
   },
   "source": [
    "# writhing encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1624108171710,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "7vOapgzxFCYS"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1624108172346,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "Rfql9HbRFUr5",
    "outputId": "0e677b01-7a3e-4de4-b09b-ea613fd9c05b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (128, 35, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (128, 1024)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1624108172915,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "befufKhtFmvs"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # we are doing this to perform addition to calculate the score\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108174088,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "4damKsu9FtHT",
    "outputId": "be8ea4ca-810a-4966-f16f-d2a1daa58e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (128, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (128, 35, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108174617,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "i0E02Jn8Fvw7"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1624108176254,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "4mRNFxJzF4AE",
    "outputId": "7232f487-b0ba-46b5-f0cf-dbd4f42e1468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (128, 3434)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1624108176931,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "BswexILJF9rz"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1624108178786,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "5CiQEZ2zGWqz"
   },
   "outputs": [],
   "source": [
    "\n",
    "checkpoint_dir = 'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iCnOdMTGZH9"
   },
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1624108180056,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "95RyH2RiGl9z"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['startseq']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 884797,
     "status": "ok",
     "timestamp": 1624109064850,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "SJhM_oxXHYnl",
    "outputId": "865889fa-30a3-4a7d-a564-293e6fc95825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 loss 2.2815701961517334\n",
      "Epoch 1 Loss 1.6391\n",
      "Time taken for 1 epoch 92.99105310440063 sec\n",
      "\n",
      "Epoch 2 Batch 0 loss 1.46639084815979\n",
      "Epoch 2 Loss 1.3358\n",
      "Time taken for 1 epoch 39.31737971305847 sec\n",
      "\n",
      "Epoch 3 Batch 0 loss 1.156550407409668\n",
      "Epoch 3 Loss 1.1297\n",
      "Time taken for 1 epoch 39.71906805038452 sec\n",
      "\n",
      "Epoch 4 Batch 0 loss 1.018256425857544\n",
      "Epoch 4 Loss 1.0250\n",
      "Time taken for 1 epoch 40.837549448013306 sec\n",
      "\n",
      "Epoch 5 Batch 0 loss 0.9535468816757202\n",
      "Epoch 5 Loss 0.9591\n",
      "Time taken for 1 epoch 40.81982159614563 sec\n",
      "\n",
      "Epoch 6 Batch 0 loss 0.8882601857185364\n",
      "Epoch 6 Loss 0.9030\n",
      "Time taken for 1 epoch 41.55751061439514 sec\n",
      "\n",
      "Epoch 7 Batch 0 loss 0.839790940284729\n",
      "Epoch 7 Loss 0.8584\n",
      "Time taken for 1 epoch 41.348894357681274 sec\n",
      "\n",
      "Epoch 8 Batch 0 loss 0.8055030703544617\n",
      "Epoch 8 Loss 0.8193\n",
      "Time taken for 1 epoch 41.95289731025696 sec\n",
      "\n",
      "Epoch 9 Batch 0 loss 0.7672399878501892\n",
      "Epoch 9 Loss 0.7811\n",
      "Time taken for 1 epoch 41.68753242492676 sec\n",
      "\n",
      "Epoch 10 Batch 0 loss 0.7310289740562439\n",
      "Epoch 10 Loss 0.7456\n",
      "Time taken for 1 epoch 42.094483375549316 sec\n",
      "\n",
      "Epoch 11 Batch 0 loss 0.7039062976837158\n",
      "Epoch 11 Loss 0.7125\n",
      "Time taken for 1 epoch 41.86745500564575 sec\n",
      "\n",
      "Epoch 12 Batch 0 loss 0.6693670749664307\n",
      "Epoch 12 Loss 0.6803\n",
      "Time taken for 1 epoch 42.37759566307068 sec\n",
      "\n",
      "Epoch 13 Batch 0 loss 0.6345837712287903\n",
      "Epoch 13 Loss 0.6471\n",
      "Time taken for 1 epoch 41.928688287734985 sec\n",
      "\n",
      "Epoch 14 Batch 0 loss 0.604195773601532\n",
      "Epoch 14 Loss 0.6153\n",
      "Time taken for 1 epoch 42.33230257034302 sec\n",
      "\n",
      "Epoch 15 Batch 0 loss 0.5711159110069275\n",
      "Epoch 15 Loss 0.5891\n",
      "Time taken for 1 epoch 41.90390133857727 sec\n",
      "\n",
      "Epoch 16 Batch 0 loss 0.5531318187713623\n",
      "Epoch 16 Loss 0.5573\n",
      "Time taken for 1 epoch 42.39460468292236 sec\n",
      "\n",
      "Epoch 17 Batch 0 loss 0.5218297243118286\n",
      "Epoch 17 Loss 0.5241\n",
      "Time taken for 1 epoch 42.02347183227539 sec\n",
      "\n",
      "Epoch 18 Batch 0 loss 0.4866788685321808\n",
      "Epoch 18 Loss 0.4928\n",
      "Time taken for 1 epoch 42.52640151977539 sec\n",
      "\n",
      "Epoch 19 Batch 0 loss 0.4790545105934143\n",
      "Epoch 19 Loss 0.4662\n",
      "Time taken for 1 epoch 42.038147926330566 sec\n",
      "\n",
      "Epoch 20 Batch 0 loss 0.4299573004245758\n",
      "Epoch 20 Loss 0.4369\n",
      "Time taken for 1 epoch 42.38642692565918 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "with tf.device('/gpu:0'):\n",
    "  for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "      batch_loss = train_step(inp, targ, enc_hidden)\n",
    "      total_loss += batch_loss\n",
    "      if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
    "    \n",
    "        \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOM3MF4XHcnz"
   },
   "source": [
    "# translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1624109064852,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "iDk3r5odHyPz"
   },
   "outputs": [],
   "source": [
    "max_target_length = 54\n",
    "max_source_length = 35\n",
    "def evaluate(sentence):\n",
    " # attention_plot = np.zeros((max_target_length, max_source_length))\n",
    "\n",
    "\n",
    "  #sentence = preprocess_sentence(sentence)\n",
    "  #print(sentence)\n",
    "  #print(source_sentence_tokenizer.word_index)\n",
    "\n",
    "  inputs = [tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=35,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([tokenizer.word_index['startseq']], 0)\n",
    "\n",
    "  for t in range(max_target_length):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "   # attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if tokenizer.index_word[predicted_id] == 'endseq':\n",
    "      #return result, sentence, attention_plot\n",
    "      return result,sentence\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  #return result, sentence, attention_plot\n",
    "  return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1624109064853,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "plRkXteuIDoJ"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  #result, sentence, attention_plot = evaluate(sentence)\n",
    "  result,sentence = evaluate(sentence)\n",
    "  \n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))\n",
    "\n",
    "  #attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "executionInfo": {
     "elapsed": 2575,
     "status": "error",
     "timestamp": 1624109068733,
     "user": {
      "displayName": "Deepak Singh",
      "photoUrl": "",
      "userId": "07841239289095029339"
     },
     "user_tz": -330
    },
    "id": "IbN53TNUW2Ux",
    "outputId": "3120c82b-8853-4fa1-cb34-ef454247bb15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: startseq regen schnee region verschwinden nord regen koennen region stern koennen sehen endseq\n",
      "Predicted translation: vor allem in der nacht regnet es hier und da fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen fällt regen der regen \n",
      "******\n",
      "startseq regen und schnee lassen an den alpen in der nacht nach im norden und nordosten fallen hier und da schauer sonst ist das klar endseq\n",
      "Input: startseq donnerstag nordwest regen region sonne wolke wechselhaft dann freitag aehnlich wetter endseq\n",
      "Predicted translation: am donnerstag regnet es im norden und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen und westen \n",
      "******\n",
      "startseq am donnerstag regen in der nordhälfte in der südhälfte mal sonne mal wolken ähnliches wetter dann auch am freitag endseq\n",
      "Input: startseq kraeftig ab morgen frueh meistens schnee schneien kalt regen endseq\n",
      "Predicted translation: und dann wird es dann auch wieder mit schnee und der fällt dann auch wieder mit schnee und der fällt dann auch wieder mit schnee und der fällt dann auch wieder mit schnee und der fällt dann auch wieder mit schnee und der fällt dann auch wieder mit schnee und der fällt dann auch \n",
      "******\n",
      "startseq vom nordmeer zieht ein kräftiges tief heran und bringt uns ab den morgenstunden heftige schneefälle zum teil auch gefrierenden regen endseq\n",
      "Input: startseq wochenende sonne samstag schoen temperatur bis siebzehn grad region endseq\n",
      "Predicted translation: und auch am samstag da wird es dann auch am samstag da wird es dann auch am samstag da wird es dann auch am samstag da wird es dann auch am samstag da wird es dann auch am samstag da wird es dann auch am samstag da wird es dann auch am samstag da \n",
      "******\n",
      "startseq sonnig geht es auch ins wochenende samstag ein herrlicher tag mit temperaturen bis siebzehn grad hier im westen endseq\n",
      "Input: startseq deutsch land morgen hoch druck kommen wolke aufloesen endseq\n",
      "Predicted translation: das hoch morgen beschert uns morgen noch einen nordmeertief das wetter morgen noch recht freundliches wetter endseq \n",
      "******\n",
      "startseq deutschland liegt morgen unter hochdruckeinfluss der die wolken weitgehend vertreibt endseq\n",
      "Input: startseq sonntag naechste nordwest wolke sonne wolke gewitter regen dabei endseq\n",
      "Predicted translation: am sonntag im westen mal wolken mal wolken und wolken und gewittern gerechnet werden endseq \n",
      "******\n",
      "startseq am sonntag im nordwesten eine mischung aus sonne und wolken mit einigen zum teil gewittrigen schauern endseq\n",
      "Input: startseq wahrscheinlich schauer gewitter stark endseq\n",
      "Predicted translation: vor allem in der sich einzelne gewitter sind mit dabei endseq \n",
      "******\n",
      "startseq örtlich schauer oder gewitter die heftig sein können endseq\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-e01010fe5644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_gloss_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"******\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_gloss_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-224-2936555d43b6>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m#result, sentence, attention_plot = evaluate(sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-223-203cc2efa097>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#print(source_sentence_tokenizer.word_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m     13\u001b[0m                                                          \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-223-203cc2efa097>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#print(source_sentence_tokenizer.word_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m     13\u001b[0m                                                          \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'im-verlauf'"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  translate(annotation_gloss_test.iloc[i,2])\n",
    "  print(\"******\")\n",
    "  print(annotation_gloss_test.iloc[i,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTyi4GqPZQex"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPKFTty/uwzxU7g8K5sXsNv",
   "collapsed_sections": [],
   "name": "gloss2German.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
